20251114 20:42:30 - MainProcess | MainThread | pdf_parser.parse_pdf:55 - DEBUG -[pdf解析之后的文本内容]: 
Test Data
This dataset contains two test samples provided by ChatGPT, an AI language model by OpenAI.
These samples include a markdown table and an English text passage, which can be used to test an
English-to-Chinese translation software supporting both text and table formats.
Text testing
The quick brown fox jumps over the lazy dog. This pangram contains every letter of the English
alphabet at least once. Pangrams are often used to test fonts, keyboards, and other text-related
tools. In addition to English, there are pangrams in many other languages. Some pangrams are more
difficult to construct due to the unique characteristics of the language.
Table Testing
20251114 20:42:30 - MainProcess | MainThread | pdf_parser.parse_pdf:61 - DEBUG -[pdf解析之后的表格内容]: 
[[['Fruit', 'Color', 'Price (USD)'], ['Apple', 'Red', '1.20'], ['Banana', 'Yellow', '0.50'], ['Orange', 'Orange', '0.80'], ['Strawberry', 'Red', '2.50'], ['Blueberry', 'Blue', '3.00'], ['Kiwi', 'Green', '1.00'], ['Mango', 'Orange', '1.50'], ['Grape', 'Purple', '2.00']]]
20251114 20:42:38 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Connection error.
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           │    │     │              └ <Request [b'POST']>
           │    │     └ <function ConnectionPool.handle_request at 0x000000002A49DE40>
           │    └ <HTTPProxy [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>
           └ <httpx.HTTPTransport object at 0x000000002A2D79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               │          └ <function TunnelHTTPConnection.handle_request at 0x000000002A49F1A0>
               └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       │    │           └ <function HTTPConnection.handle_request at 0x000000002A49D080>
                       │    └ <HTTPConnection [CONNECTION FAILED]>
                       └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             │    │        └ <Request [b'CONNECT']>
             │    └ <function HTTPConnection._connect at 0x000000002A49D120>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             │    │                │             └ {'host': '127.0.0.1', 'port': 7890, 'local_address': None, 'timeout': None, 'socket_options': None}
             │    │                └ <function SyncBackend.connect_tcp at 0x000000002A43D580>
             │    └ <httpcore.SyncBackend object at 0x000000002A2D7D90>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         │              └ {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>}
         └ <function map_exceptions at 0x000000002A413CE0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None)
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_exceptions at 0x000000002A9D3C40>
    └ <contextlib._GeneratorContextManager object at 0x000000002A989E80>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
          └ <class 'httpcore.ConnectError'>

httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               │    │       └ <function Client.send at 0x0000000028073060>
               │    └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
               └ <openai.OpenAI object at 0x000000002A29F770>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               │    └ <function Client._send_handling_auth at 0x0000000028073100>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               │    └ <function Client._send_handling_redirects at 0x00000000280731A0>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               │    │                    └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │    └ <function Client._send_single_request at 0x0000000028073240>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               │         │              └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │         └ <function HTTPTransport.handle_request at 0x00000000280705E0>
               └ <httpx.HTTPTransport object at 0x000000002A2D79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         └ <function map_httpcore_exceptions at 0x00000000280700E0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectError(ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None))
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_httpcore_exceptions at 0x000000002A95BE40>
    └ <contextlib._GeneratorContextManager object at 0x000000002A989B00>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
          │          └ '[WinError 10061] 由于目标计算机积极拒绝，无法连接。'
          └ <class 'httpx.ConnectError'>

httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 20, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          └ <function PDFTranslator.translate_book at 0x000000002885A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
                               │    │     │   │        │                └ 'Japanese'
                               │    │     │   │        └ 'English'
                               │    │     │   └ <book.content.Content object at 0x000000002A9A5FD0>
                               │    │     └ <function TranslatorChain.run at 0x000000002885A200>
                               │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>
                               └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286A7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9D2990>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Japanese', additional...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2BC180>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002AB34B00>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2BC860>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB44390>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Japanese', additional_kwargs={}, response_met...
           │    └ <function BaseChatModel.generate at 0x000000002A2BC720>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2BC9A0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A325E40>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'gpt-4o', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English...
                   │    │      │                 └ <function Completions.create at 0x000000002A98FBA0>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A9A6F90>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'gpt-4o', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x00000000018CCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'gpt-4o', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>,)
           └ <function Completions.create at 0x000000002A5F4FE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A29F770>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE65C0>
           │    │          └ <openai.OpenAI object at 0x000000002A29F770>
           │    └ ~ResponseT
           └ <function cast at 0x00000000018CCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
          │                          └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
          └ <class 'openai.APIConnectionError'>

openai.APIConnectionError: Connection error.
20251114 20:42:38 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 20:42:38 - MainProcess | MainThread | content.set_translation:35 - WARNING -当前翻译之后的文本内容不是字符串，请检查！
20251114 20:42:38 - MainProcess | MainThread | translator_chain.run:36 - INFO -+++++++++++++
20251114 20:42:46 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Connection error.
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           │    │     │              └ <Request [b'POST']>
           │    │     └ <function ConnectionPool.handle_request at 0x000000002A49DE40>
           │    └ <HTTPProxy [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>
           └ <httpx.HTTPTransport object at 0x000000002A2D79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               │          └ <function TunnelHTTPConnection.handle_request at 0x000000002A49F1A0>
               └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       │    │           └ <function HTTPConnection.handle_request at 0x000000002A49D080>
                       │    └ <HTTPConnection [CONNECTION FAILED]>
                       └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             │    │        └ <Request [b'CONNECT']>
             │    └ <function HTTPConnection._connect at 0x000000002A49D120>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             │    │                │             └ {'host': '127.0.0.1', 'port': 7890, 'local_address': None, 'timeout': None, 'socket_options': None}
             │    │                └ <function SyncBackend.connect_tcp at 0x000000002A43D580>
             │    └ <httpcore.SyncBackend object at 0x000000002A2D7D90>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         │              └ {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>}
         └ <function map_exceptions at 0x000000002A413CE0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None)
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_exceptions at 0x000000002AB616C0>
    └ <contextlib._GeneratorContextManager object at 0x000000002C00D550>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
          └ <class 'httpcore.ConnectError'>

httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               │    │       └ <function Client.send at 0x0000000028073060>
               │    └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
               └ <openai.OpenAI object at 0x000000002A29F770>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               │    └ <function Client._send_handling_auth at 0x0000000028073100>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               │    └ <function Client._send_handling_redirects at 0x00000000280731A0>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               │    │                    └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │    └ <function Client._send_single_request at 0x0000000028073240>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               │         │              └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │         └ <function HTTPTransport.handle_request at 0x00000000280705E0>
               └ <httpx.HTTPTransport object at 0x000000002A2D79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         └ <function map_httpcore_exceptions at 0x00000000280700E0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectError(ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None))
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_httpcore_exceptions at 0x000000002AB5DF40>
    └ <contextlib._GeneratorContextManager object at 0x000000002C00D630>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
          │          └ '[WinError 10061] 由于目标计算机积极拒绝，无法连接。'
          └ <class 'httpx.ConnectError'>

httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 20, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          └ <function PDFTranslator.translate_book at 0x000000002885A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
    │                          │    │     │   │        │                └ 'Japanese'
    │                          │    │     │   │        └ 'English'
    │                          │    │     │   └ <book.content.TableContent object at 0x000000002A9A5BE0>
    │                          │    │     └ <function TranslatorChain.run at 0x000000002885A200>
    │                          │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>
    │                          └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>
    └ ''

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286A7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB825D0>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Japanese', additional...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2BC180>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002BFF3900>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2BC860>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002ABC7450>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Japanese', additional_kwargs={}, response_met...
           │    └ <function BaseChatModel.generate at 0x000000002A2BC720>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2BC9A0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A325E40>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'gpt-4o', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English...
                   │    │      │                 └ <function Completions.create at 0x000000002A98FBA0>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A9A6F90>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'gpt-4o', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x00000000018CCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'gpt-4o', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>,)
           └ <function Completions.create at 0x000000002A5F4FE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A29F770>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE65C0>
           │    │          └ <openai.OpenAI object at 0x000000002A29F770>
           │    └ ~ResponseT
           └ <function cast at 0x00000000018CCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
          │                          └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
          └ <class 'openai.APIConnectionError'>

openai.APIConnectionError: Connection error.
20251114 20:42:46 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 20:42:46 - MainProcess | MainThread | file_writer.save_book_markdown:105 - DEBUG -原文件路径是：test/test.pdf, 翻译之后的输出文件路径: test/test_translated.md
20251114 20:42:46 - MainProcess | MainThread | file_writer.save_book_markdown:134 - INFO -MarkDown文件写入完成！
20251114 20:43:24 - MainProcess | MainThread | pdf_parser.parse_pdf:55 - DEBUG -[pdf解析之后的文本内容]: 
Test Data
This dataset contains two test samples provided by ChatGPT, an AI language model by OpenAI.
These samples include a markdown table and an English text passage, which can be used to test an
English-to-Chinese translation software supporting both text and table formats.
Text testing
The quick brown fox jumps over the lazy dog. This pangram contains every letter of the English
alphabet at least once. Pangrams are often used to test fonts, keyboards, and other text-related
tools. In addition to English, there are pangrams in many other languages. Some pangrams are more
difficult to construct due to the unique characteristics of the language.
Table Testing
20251114 20:43:24 - MainProcess | MainThread | pdf_parser.parse_pdf:61 - DEBUG -[pdf解析之后的表格内容]: 
[[['Fruit', 'Color', 'Price (USD)'], ['Apple', 'Red', '1.20'], ['Banana', 'Yellow', '0.50'], ['Orange', 'Orange', '0.80'], ['Strawberry', 'Red', '2.50'], ['Blueberry', 'Blue', '3.00'], ['Kiwi', 'Green', '1.00'], ['Mango', 'Orange', '1.50'], ['Grape', 'Purple', '2.00']]]
20251114 20:43:32 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Connection error.
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           │    │     │              └ <Request [b'POST']>
           │    │     └ <function ConnectionPool.handle_request at 0x000000002A4ADE40>
           │    └ <HTTPProxy [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>
           └ <httpx.HTTPTransport object at 0x000000002A2E79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               │          └ <function TunnelHTTPConnection.handle_request at 0x000000002A4AF1A0>
               └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       │    │           └ <function HTTPConnection.handle_request at 0x000000002A4AD080>
                       │    └ <HTTPConnection [CONNECTION FAILED]>
                       └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             │    │        └ <Request [b'CONNECT']>
             │    └ <function HTTPConnection._connect at 0x000000002A4AD120>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             │    │                │             └ {'host': '127.0.0.1', 'port': 7890, 'local_address': None, 'timeout': None, 'socket_options': None}
             │    │                └ <function SyncBackend.connect_tcp at 0x000000002A44D580>
             │    └ <httpcore.SyncBackend object at 0x000000002A2E7D90>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         │              └ {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>}
         └ <function map_exceptions at 0x000000002A423CE0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None)
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_exceptions at 0x000000002A9E3C40>
    └ <contextlib._GeneratorContextManager object at 0x000000002A999E80>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
          └ <class 'httpcore.ConnectError'>

httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               │    │       └ <function Client.send at 0x0000000028083060>
               │    └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A2AF0E0>
               └ <openai.OpenAI object at 0x000000002A2AF770>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               │    └ <function Client._send_handling_auth at 0x0000000028083100>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A2AF0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               │    └ <function Client._send_handling_redirects at 0x00000000280831A0>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A2AF0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               │    │                    └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │    └ <function Client._send_single_request at 0x0000000028083240>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A2AF0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               │         │              └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │         └ <function HTTPTransport.handle_request at 0x00000000280805E0>
               └ <httpx.HTTPTransport object at 0x000000002A2E79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         └ <function map_httpcore_exceptions at 0x00000000280800E0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectError(ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None))
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_httpcore_exceptions at 0x000000002A96BE40>
    └ <contextlib._GeneratorContextManager object at 0x000000002A999B00>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
          │          └ '[WinError 10061] 由于目标计算机积极拒绝，无法连接。'
          └ <class 'httpx.ConnectError'>

httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 20, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          └ <function PDFTranslator.translate_book at 0x000000002886A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A2AECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
                               │    │     │   │        │                └ 'Japanese'
                               │    │     │   │        └ 'English'
                               │    │     │   └ <book.content.Content object at 0x000000002A9B5FD0>
                               │    │     └ <function TranslatorChain.run at 0x000000002886A200>
                               │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A2AEE40>
                               └ <translator.book_translator.PDFTranslator object at 0x000000002A2AECF0>

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286B7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A2AEE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9E2990>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Japanese', additional...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2CC220>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002AB440C0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2CC860>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB50390>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Japanese', additional_kwargs={}, response_met...
           │    └ <function BaseChatModel.generate at 0x000000002A2CC720>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2CC9A0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A335E40>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'gpt-4o', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English...
                   │    │      │                 └ <function Completions.create at 0x000000002A99FBA0>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A9B6F90>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'gpt-4o', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x00000000018FCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'gpt-4o', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>,)
           └ <function Completions.create at 0x000000002A604FE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A2AF770>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE25C0>
           │    │          └ <openai.OpenAI object at 0x000000002A2AF770>
           │    └ ~ResponseT
           └ <function cast at 0x00000000018FCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
          │                          └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
          └ <class 'openai.APIConnectionError'>

openai.APIConnectionError: Connection error.
20251114 20:43:32 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 20:43:32 - MainProcess | MainThread | content.set_translation:35 - WARNING -当前翻译之后的文本内容不是字符串，请检查！
20251114 20:43:32 - MainProcess | MainThread | translator_chain.run:36 - INFO -+++++++++++++
20251114 20:43:39 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Connection error.
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           │    │     │              └ <Request [b'POST']>
           │    │     └ <function ConnectionPool.handle_request at 0x000000002A4ADE40>
           │    └ <HTTPProxy [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>
           └ <httpx.HTTPTransport object at 0x000000002A2E79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               │          └ <function TunnelHTTPConnection.handle_request at 0x000000002A4AF1A0>
               └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       │    │           └ <function HTTPConnection.handle_request at 0x000000002A4AD080>
                       │    └ <HTTPConnection [CONNECTION FAILED]>
                       └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             │    │        └ <Request [b'CONNECT']>
             │    └ <function HTTPConnection._connect at 0x000000002A4AD120>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             │    │                │             └ {'host': '127.0.0.1', 'port': 7890, 'local_address': None, 'timeout': None, 'socket_options': None}
             │    │                └ <function SyncBackend.connect_tcp at 0x000000002A44D580>
             │    └ <httpcore.SyncBackend object at 0x000000002A2E7D90>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         │              └ {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>}
         └ <function map_exceptions at 0x000000002A423CE0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None)
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_exceptions at 0x000000002AB716C0>
    └ <contextlib._GeneratorContextManager object at 0x000000002BF1D550>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
          └ <class 'httpcore.ConnectError'>

httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               │    │       └ <function Client.send at 0x0000000028083060>
               │    └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A2AF0E0>
               └ <openai.OpenAI object at 0x000000002A2AF770>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               │    └ <function Client._send_handling_auth at 0x0000000028083100>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A2AF0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               │    └ <function Client._send_handling_redirects at 0x00000000280831A0>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A2AF0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               │    │                    └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │    └ <function Client._send_single_request at 0x0000000028083240>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A2AF0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               │         │              └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │         └ <function HTTPTransport.handle_request at 0x00000000280805E0>
               └ <httpx.HTTPTransport object at 0x000000002A2E79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         └ <function map_httpcore_exceptions at 0x00000000280800E0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectError(ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None))
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_httpcore_exceptions at 0x000000002AB6DF40>
    └ <contextlib._GeneratorContextManager object at 0x000000002BF1D630>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
          │          └ '[WinError 10061] 由于目标计算机积极拒绝，无法连接。'
          └ <class 'httpx.ConnectError'>

httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 20, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          └ <function PDFTranslator.translate_book at 0x000000002886A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A2AECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
    │                          │    │     │   │        │                └ 'Japanese'
    │                          │    │     │   │        └ 'English'
    │                          │    │     │   └ <book.content.TableContent object at 0x000000002A9B5BE0>
    │                          │    │     └ <function TranslatorChain.run at 0x000000002886A200>
    │                          │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A2AEE40>
    │                          └ <translator.book_translator.PDFTranslator object at 0x000000002A2AECF0>
    └ ''

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286B7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A2AEE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB925D0>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Japanese', additional...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2CC220>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002BF038C0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2CC860>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002ABDB450>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Japanese', additional_kwargs={}, response_met...
           │    └ <function BaseChatModel.generate at 0x000000002A2CC720>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2CC9A0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A335E40>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'gpt-4o', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English...
                   │    │      │                 └ <function Completions.create at 0x000000002A99FBA0>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A9B6F90>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'gpt-4o', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x00000000018FCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'gpt-4o', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>,)
           └ <function Completions.create at 0x000000002A604FE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A2AF770>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A47FCB0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE25C0>
           │    │          └ <openai.OpenAI object at 0x000000002A2AF770>
           │    └ ~ResponseT
           └ <function cast at 0x00000000018FCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
          │                          └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
          └ <class 'openai.APIConnectionError'>

openai.APIConnectionError: Connection error.
20251114 20:43:39 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 20:43:39 - MainProcess | MainThread | file_writer.save_book_markdown:105 - DEBUG -原文件路径是：test/test.pdf, 翻译之后的输出文件路径: test/test_translated.md
20251114 20:43:39 - MainProcess | MainThread | file_writer.save_book_markdown:134 - INFO -MarkDown文件写入完成！
20251114 20:49:57 - MainProcess | MainThread | pdf_parser.parse_pdf:55 - DEBUG -[pdf解析之后的文本内容]: 
Test Data
This dataset contains two test samples provided by ChatGPT, an AI language model by OpenAI.
These samples include a markdown table and an English text passage, which can be used to test an
English-to-Chinese translation software supporting both text and table formats.
Text testing
The quick brown fox jumps over the lazy dog. This pangram contains every letter of the English
alphabet at least once. Pangrams are often used to test fonts, keyboards, and other text-related
tools. In addition to English, there are pangrams in many other languages. Some pangrams are more
difficult to construct due to the unique characteristics of the language.
Table Testing
20251114 20:49:57 - MainProcess | MainThread | pdf_parser.parse_pdf:61 - DEBUG -[pdf解析之后的表格内容]: 
[[['Fruit', 'Color', 'Price (USD)'], ['Apple', 'Red', '1.20'], ['Banana', 'Yellow', '0.50'], ['Orange', 'Orange', '0.80'], ['Strawberry', 'Red', '2.50'], ['Blueberry', 'Blue', '3.00'], ['Kiwi', 'Green', '1.00'], ['Mango', 'Orange', '1.50'], ['Grape', 'Purple', '2.00']]]
20251114 20:50:05 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Connection error.
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           │    │     │              └ <Request [b'POST']>
           │    │     └ <function ConnectionPool.handle_request at 0x000000002A49DE40>
           │    └ <HTTPProxy [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>
           └ <httpx.HTTPTransport object at 0x000000002A2D39D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               │          └ <function TunnelHTTPConnection.handle_request at 0x000000002A49F1A0>
               └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       │    │           └ <function HTTPConnection.handle_request at 0x000000002A49D080>
                       │    └ <HTTPConnection [CONNECTION FAILED]>
                       └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             │    │        └ <Request [b'CONNECT']>
             │    └ <function HTTPConnection._connect at 0x000000002A49D120>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             │    │                │             └ {'host': '127.0.0.1', 'port': 7890, 'local_address': None, 'timeout': None, 'socket_options': None}
             │    │                └ <function SyncBackend.connect_tcp at 0x000000002A43D580>
             │    └ <httpcore.SyncBackend object at 0x000000002A2D3D90>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         │              └ {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>}
         └ <function map_exceptions at 0x000000002A413CE0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None)
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_exceptions at 0x000000002A9D3C40>
    └ <contextlib._GeneratorContextManager object at 0x000000002A989E80>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
          └ <class 'httpcore.ConnectError'>

httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               │    │       └ <function Client.send at 0x0000000028073060>
               │    └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
               └ <openai.OpenAI object at 0x000000002A29F770>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               │    └ <function Client._send_handling_auth at 0x0000000028073100>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               │    └ <function Client._send_handling_redirects at 0x00000000280731A0>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               │    │                    └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │    └ <function Client._send_single_request at 0x0000000028073240>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               │         │              └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │         └ <function HTTPTransport.handle_request at 0x00000000280705E0>
               └ <httpx.HTTPTransport object at 0x000000002A2D39D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         └ <function map_httpcore_exceptions at 0x00000000280700E0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectError(ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None))
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_httpcore_exceptions at 0x000000002A95BE40>
    └ <contextlib._GeneratorContextManager object at 0x000000002A989B00>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
          │          └ '[WinError 10061] 由于目标计算机积极拒绝，无法连接。'
          └ <class 'httpx.ConnectError'>

httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 20, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          └ <function PDFTranslator.translate_book at 0x000000002885A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
                               │    │     │   │        │                └ 'Chinese'
                               │    │     │   │        └ 'English'
                               │    │     │   └ <book.content.Content object at 0x000000002A9A5FD0>
                               │    │     └ <function TranslatorChain.run at 0x000000002885A200>
                               │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>
                               └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286A7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9D2990>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2C0220>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002AB36080>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2C0860>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB40390>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2C0720>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2C09A0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A325E40>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A98FB00>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A9A6F90>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x000000000192CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>,)
           └ <function Completions.create at 0x000000002A5F4FE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A29F770>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE25C0>
           │    │          └ <openai.OpenAI object at 0x000000002A29F770>
           │    └ ~ResponseT
           └ <function cast at 0x000000000192CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
          │                          └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
          └ <class 'openai.APIConnectionError'>

openai.APIConnectionError: Connection error.
20251114 20:50:05 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 20:50:05 - MainProcess | MainThread | content.set_translation:35 - WARNING -当前翻译之后的文本内容不是字符串，请检查！
20251114 20:50:05 - MainProcess | MainThread | translator_chain.run:36 - INFO -+++++++++++++
20251114 20:50:12 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Connection error.
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           │    │     │              └ <Request [b'POST']>
           │    │     └ <function ConnectionPool.handle_request at 0x000000002A49DE40>
           │    └ <HTTPProxy [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>
           └ <httpx.HTTPTransport object at 0x000000002A2D39D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               │          └ <function TunnelHTTPConnection.handle_request at 0x000000002A49F1A0>
               └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       │    │           └ <function HTTPConnection.handle_request at 0x000000002A49D080>
                       │    └ <HTTPConnection [CONNECTION FAILED]>
                       └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             │    │        └ <Request [b'CONNECT']>
             │    └ <function HTTPConnection._connect at 0x000000002A49D120>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             │    │                │             └ {'host': '127.0.0.1', 'port': 7890, 'local_address': None, 'timeout': None, 'socket_options': None}
             │    │                └ <function SyncBackend.connect_tcp at 0x000000002A43D580>
             │    └ <httpcore.SyncBackend object at 0x000000002A2D3D90>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         │              └ {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>}
         └ <function map_exceptions at 0x000000002A413CE0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None)
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_exceptions at 0x000000002AB616C0>
    └ <contextlib._GeneratorContextManager object at 0x000000002BF0D550>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
          └ <class 'httpcore.ConnectError'>

httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               │    │       └ <function Client.send at 0x0000000028073060>
               │    └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
               └ <openai.OpenAI object at 0x000000002A29F770>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               │    └ <function Client._send_handling_auth at 0x0000000028073100>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               │    └ <function Client._send_handling_redirects at 0x00000000280731A0>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               │    │                    └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │    └ <function Client._send_single_request at 0x0000000028073240>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               │         │              └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │         └ <function HTTPTransport.handle_request at 0x00000000280705E0>
               └ <httpx.HTTPTransport object at 0x000000002A2D39D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         └ <function map_httpcore_exceptions at 0x00000000280700E0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectError(ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None))
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_httpcore_exceptions at 0x000000002AB5DF40>
    └ <contextlib._GeneratorContextManager object at 0x000000002BF0D630>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
          │          └ '[WinError 10061] 由于目标计算机积极拒绝，无法连接。'
          └ <class 'httpx.ConnectError'>

httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 20, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          └ <function PDFTranslator.translate_book at 0x000000002885A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
    │                          │    │     │   │        │                └ 'Chinese'
    │                          │    │     │   │        └ 'English'
    │                          │    │     │   └ <book.content.TableContent object at 0x000000002A9A5BE0>
    │                          │    │     └ <function TranslatorChain.run at 0x000000002885A200>
    │                          │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>
    │                          └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>
    └ ''

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286A7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB825D0>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2C0220>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002BEEFAC0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2C0860>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002ABCB450>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2C0720>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2C09A0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A325E40>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A98FB00>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A9A6F90>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x000000000192CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>,)
           └ <function Completions.create at 0x000000002A5F4FE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A29F770>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE25C0>
           │    │          └ <openai.OpenAI object at 0x000000002A29F770>
           │    └ ~ResponseT
           └ <function cast at 0x000000000192CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
          │                          └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
          └ <class 'openai.APIConnectionError'>

openai.APIConnectionError: Connection error.
20251114 20:50:12 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 20:50:12 - MainProcess | MainThread | file_writer.save_book_markdown:105 - DEBUG -原文件路径是：test/test.pdf, 翻译之后的输出文件路径: test/test_translated.md
20251114 20:50:12 - MainProcess | MainThread | file_writer.save_book_markdown:134 - INFO -MarkDown文件写入完成！
20251114 20:51:22 - MainProcess | MainThread | pdf_parser.parse_pdf:55 - DEBUG -[pdf解析之后的文本内容]: 
Test Data
This dataset contains two test samples provided by ChatGPT, an AI language model by OpenAI.
These samples include a markdown table and an English text passage, which can be used to test an
English-to-Chinese translation software supporting both text and table formats.
Text testing
The quick brown fox jumps over the lazy dog. This pangram contains every letter of the English
alphabet at least once. Pangrams are often used to test fonts, keyboards, and other text-related
tools. In addition to English, there are pangrams in many other languages. Some pangrams are more
difficult to construct due to the unique characteristics of the language.
Table Testing
20251114 20:51:22 - MainProcess | MainThread | pdf_parser.parse_pdf:61 - DEBUG -[pdf解析之后的表格内容]: 
[[['Fruit', 'Color', 'Price (USD)'], ['Apple', 'Red', '1.20'], ['Banana', 'Yellow', '0.50'], ['Orange', 'Orange', '0.80'], ['Strawberry', 'Red', '2.50'], ['Blueberry', 'Blue', '3.00'], ['Kiwi', 'Green', '1.00'], ['Mango', 'Orange', '1.50'], ['Grape', 'Purple', '2.00']]]
20251114 20:51:30 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Connection error.
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           │    │     │              └ <Request [b'POST']>
           │    │     └ <function ConnectionPool.handle_request at 0x000000002A49DE40>
           │    └ <HTTPProxy [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>
           └ <httpx.HTTPTransport object at 0x000000002A2D39D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               │          └ <function TunnelHTTPConnection.handle_request at 0x000000002A49F1A0>
               └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       │    │           └ <function HTTPConnection.handle_request at 0x000000002A49D080>
                       │    └ <HTTPConnection [CONNECTION FAILED]>
                       └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             │    │        └ <Request [b'CONNECT']>
             │    └ <function HTTPConnection._connect at 0x000000002A49D120>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             │    │                │             └ {'host': '127.0.0.1', 'port': 7890, 'local_address': None, 'timeout': None, 'socket_options': None}
             │    │                └ <function SyncBackend.connect_tcp at 0x000000002A43D580>
             │    └ <httpcore.SyncBackend object at 0x000000002A2D3D90>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         │              └ {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>}
         └ <function map_exceptions at 0x000000002A413CE0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None)
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_exceptions at 0x000000002A9D3C40>
    └ <contextlib._GeneratorContextManager object at 0x000000002A989E80>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
          └ <class 'httpcore.ConnectError'>

httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               │    │       └ <function Client.send at 0x0000000028083060>
               │    └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
               └ <openai.OpenAI object at 0x000000002A29F770>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               │    └ <function Client._send_handling_auth at 0x0000000028083100>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               │    └ <function Client._send_handling_redirects at 0x00000000280831A0>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               │    │                    └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │    └ <function Client._send_single_request at 0x0000000028083240>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               │         │              └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │         └ <function HTTPTransport.handle_request at 0x00000000280805E0>
               └ <httpx.HTTPTransport object at 0x000000002A2D39D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         └ <function map_httpcore_exceptions at 0x00000000280800E0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectError(ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None))
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_httpcore_exceptions at 0x000000002A95BE40>
    └ <contextlib._GeneratorContextManager object at 0x000000002A989B00>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
          │          └ '[WinError 10061] 由于目标计算机积极拒绝，无法连接。'
          └ <class 'httpx.ConnectError'>

httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 20, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          └ <function PDFTranslator.translate_book at 0x000000002886A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
                               │    │     │   │        │                └ 'Chinese'
                               │    │     │   │        └ 'English'
                               │    │     │   └ <book.content.Content object at 0x000000002A9A5FD0>
                               │    │     └ <function TranslatorChain.run at 0x000000002886A200>
                               │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>
                               └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286B7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9D2990>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2C0220>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002AB36280>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2C0860>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB44390>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2C0720>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2C09A0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A325E40>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A98FBA0>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A9A6F90>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x000000000187CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>,)
           └ <function Completions.create at 0x000000002A5F4FE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A29F770>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE25C0>
           │    │          └ <openai.OpenAI object at 0x000000002A29F770>
           │    └ ~ResponseT
           └ <function cast at 0x000000000187CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
          │                          └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
          └ <class 'openai.APIConnectionError'>

openai.APIConnectionError: Connection error.
20251114 20:51:30 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 20:51:30 - MainProcess | MainThread | content.set_translation:35 - WARNING -当前翻译之后的文本内容不是字符串，请检查！
20251114 20:51:30 - MainProcess | MainThread | translator_chain.run:36 - INFO -+++++++++++++
20251114 20:51:37 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Connection error.
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           │    │     │              └ <Request [b'POST']>
           │    │     └ <function ConnectionPool.handle_request at 0x000000002A49DE40>
           │    └ <HTTPProxy [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>
           └ <httpx.HTTPTransport object at 0x000000002A2D39D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               │          └ <function TunnelHTTPConnection.handle_request at 0x000000002A49F1A0>
               └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       │    │           └ <function HTTPConnection.handle_request at 0x000000002A49D080>
                       │    └ <HTTPConnection [CONNECTION FAILED]>
                       └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             │    │        └ <Request [b'CONNECT']>
             │    └ <function HTTPConnection._connect at 0x000000002A49D120>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             │    │                │             └ {'host': '127.0.0.1', 'port': 7890, 'local_address': None, 'timeout': None, 'socket_options': None}
             │    │                └ <function SyncBackend.connect_tcp at 0x000000002A43D580>
             │    └ <httpcore.SyncBackend object at 0x000000002A2D3D90>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         │              └ {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>}
         └ <function map_exceptions at 0x000000002A413CE0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None)
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_exceptions at 0x000000002AB616C0>
    └ <contextlib._GeneratorContextManager object at 0x000000002BF11550>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
          └ <class 'httpcore.ConnectError'>

httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               │    │       └ <function Client.send at 0x0000000028083060>
               │    └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
               └ <openai.OpenAI object at 0x000000002A29F770>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               │    └ <function Client._send_handling_auth at 0x0000000028083100>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               │    └ <function Client._send_handling_redirects at 0x00000000280831A0>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               │    │                    └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │    └ <function Client._send_single_request at 0x0000000028083240>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               │         │              └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │         └ <function HTTPTransport.handle_request at 0x00000000280805E0>
               └ <httpx.HTTPTransport object at 0x000000002A2D39D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         └ <function map_httpcore_exceptions at 0x00000000280800E0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectError(ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None))
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_httpcore_exceptions at 0x000000002AB5DF40>
    └ <contextlib._GeneratorContextManager object at 0x000000002BF11630>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
          │          └ '[WinError 10061] 由于目标计算机积极拒绝，无法连接。'
          └ <class 'httpx.ConnectError'>

httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 20, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          └ <function PDFTranslator.translate_book at 0x000000002886A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
    │                          │    │     │   │        │                └ 'Chinese'
    │                          │    │     │   │        └ 'English'
    │                          │    │     │   └ <book.content.TableContent object at 0x000000002A9A5BE0>
    │                          │    │     └ <function TranslatorChain.run at 0x000000002886A200>
    │                          │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>
    │                          └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>
    └ ''

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286B7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB825D0>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2C0220>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002BEF3940>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2C0860>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002ABCB450>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2C0720>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2C09A0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A325E40>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A98FBA0>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A9A6F90>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x000000000187CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>,)
           └ <function Completions.create at 0x000000002A5F4FE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A29F770>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE25C0>
           │    │          └ <openai.OpenAI object at 0x000000002A29F770>
           │    └ ~ResponseT
           └ <function cast at 0x000000000187CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
          │                          └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
          └ <class 'openai.APIConnectionError'>

openai.APIConnectionError: Connection error.
20251114 20:51:37 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 20:51:37 - MainProcess | MainThread | file_writer.save_book_pdf:46 - DEBUG -pdf原文件路径是：test/test.pdf, 翻译之后的输出文件路径: test/test_translated.pdf
20251114 20:51:37 - MainProcess | MainThread | file_writer.save_book_pdf:92 - INFO -pdf文件写入完成！
20251114 21:01:28 - MainProcess | MainThread | pdf_parser.parse_pdf:55 - DEBUG -[pdf解析之后的文本内容]: 
Test Data
This dataset contains two test samples provided by ChatGPT, an AI language model by OpenAI.
These samples include a markdown table and an English text passage, which can be used to test an
English-to-Chinese translation software supporting both text and table formats.
Text testing
The quick brown fox jumps over the lazy dog. This pangram contains every letter of the English
alphabet at least once. Pangrams are often used to test fonts, keyboards, and other text-related
tools. In addition to English, there are pangrams in many other languages. Some pangrams are more
difficult to construct due to the unique characteristics of the language.
Table Testing
20251114 21:01:28 - MainProcess | MainThread | pdf_parser.parse_pdf:61 - DEBUG -[pdf解析之后的表格内容]: 
[[['Fruit', 'Color', 'Price (USD)'], ['Apple', 'Red', '1.20'], ['Banana', 'Yellow', '0.50'], ['Orange', 'Orange', '0.80'], ['Strawberry', 'Red', '2.50'], ['Blueberry', 'Blue', '3.00'], ['Kiwi', 'Green', '1.00'], ['Mango', 'Orange', '1.50'], ['Grape', 'Purple', '2.00']]]
20251114 21:01:35 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Connection error.
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           │    │     │              └ <Request [b'POST']>
           │    │     └ <function ConnectionPool.handle_request at 0x000000002A48DEE0>
           │    └ <HTTPProxy [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>
           └ <httpx.HTTPTransport object at 0x000000002A2C39D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               │          └ <function TunnelHTTPConnection.handle_request at 0x000000002A48F240>
               └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       │    │           └ <function HTTPConnection.handle_request at 0x000000002A48D120>
                       │    └ <HTTPConnection [CONNECTION FAILED]>
                       └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             │    │        └ <Request [b'CONNECT']>
             │    └ <function HTTPConnection._connect at 0x000000002A48D1C0>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             │    │                │             └ {'host': '127.0.0.1', 'port': 7890, 'local_address': None, 'timeout': None, 'socket_options': None}
             │    │                └ <function SyncBackend.connect_tcp at 0x000000002A42D620>
             │    └ <httpcore.SyncBackend object at 0x000000002A2C3D90>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         │              └ {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>}
         └ <function map_exceptions at 0x000000002A403D80>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None)
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_exceptions at 0x000000002A9C3C40>
    └ <contextlib._GeneratorContextManager object at 0x000000002A97DE10>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
          └ <class 'httpcore.ConnectError'>

httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               │    │       └ <function Client.send at 0x0000000028073060>
               │    └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
               └ <openai.OpenAI object at 0x000000002A28F770>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               │    └ <function Client._send_handling_auth at 0x0000000028073100>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               │    └ <function Client._send_handling_redirects at 0x00000000280731A0>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               │    │                    └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │    └ <function Client._send_single_request at 0x0000000028073240>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               │         │              └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │         └ <function HTTPTransport.handle_request at 0x00000000280705E0>
               └ <httpx.HTTPTransport object at 0x000000002A2C39D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         └ <function map_httpcore_exceptions at 0x00000000280700E0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectError(ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None))
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_httpcore_exceptions at 0x000000002A94BD40>
    └ <contextlib._GeneratorContextManager object at 0x000000002A97DA90>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
          │          └ '[WinError 10061] 由于目标计算机积极拒绝，无法连接。'
          └ <class 'httpx.ConnectError'>

httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 20, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          └ <function PDFTranslator.translate_book at 0x000000002885A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A28ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
                               │    │     │   │        │                └ 'Chinese'
                               │    │     │   │        └ 'English'
                               │    │     │   └ <book.content.Content object at 0x000000002A995FD0>
                               │    │     └ <function TranslatorChain.run at 0x000000002885A200>
                               │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A28EE40>
                               └ <translator.book_translator.PDFTranslator object at 0x000000002A28ECF0>

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286A7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A28EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9C2990>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2AC2C0>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002AB21300>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2AC900>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB34390>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2AC7C0>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2ACA40>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A315EE0>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A983BA0>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A996F90>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x000000000191CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>,)
           └ <function Completions.create at 0x000000002A5E5080>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A28F770>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE2660>
           │    │          └ <openai.OpenAI object at 0x000000002A28F770>
           │    └ ~ResponseT
           └ <function cast at 0x000000000191CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
          │                          └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
          └ <class 'openai.APIConnectionError'>

openai.APIConnectionError: Connection error.
20251114 21:01:35 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 21:01:35 - MainProcess | MainThread | content.set_translation:35 - WARNING -当前翻译之后的文本内容不是字符串，请检查！
20251114 21:01:35 - MainProcess | MainThread | translator_chain.run:36 - INFO -+++++++++++++
20251114 21:01:43 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Connection error.
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           │    │     │              └ <Request [b'POST']>
           │    │     └ <function ConnectionPool.handle_request at 0x000000002A48DEE0>
           │    └ <HTTPProxy [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>
           └ <httpx.HTTPTransport object at 0x000000002A2C39D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               │          └ <function TunnelHTTPConnection.handle_request at 0x000000002A48F240>
               └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       │    │           └ <function HTTPConnection.handle_request at 0x000000002A48D120>
                       │    └ <HTTPConnection [CONNECTION FAILED]>
                       └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             │    │        └ <Request [b'CONNECT']>
             │    └ <function HTTPConnection._connect at 0x000000002A48D1C0>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             │    │                │             └ {'host': '127.0.0.1', 'port': 7890, 'local_address': None, 'timeout': None, 'socket_options': None}
             │    │                └ <function SyncBackend.connect_tcp at 0x000000002A42D620>
             │    └ <httpcore.SyncBackend object at 0x000000002A2C3D90>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         │              └ {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>}
         └ <function map_exceptions at 0x000000002A403D80>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None)
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_exceptions at 0x000000002AB4D6C0>
    └ <contextlib._GeneratorContextManager object at 0x000000002BFFD4E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
          └ <class 'httpcore.ConnectError'>

httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               │    │       └ <function Client.send at 0x0000000028073060>
               │    └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
               └ <openai.OpenAI object at 0x000000002A28F770>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               │    └ <function Client._send_handling_auth at 0x0000000028073100>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               │    └ <function Client._send_handling_redirects at 0x00000000280731A0>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               │    │                    └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │    └ <function Client._send_single_request at 0x0000000028073240>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               │         │              └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │         └ <function HTTPTransport.handle_request at 0x00000000280705E0>
               └ <httpx.HTTPTransport object at 0x000000002A2C39D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         └ <function map_httpcore_exceptions at 0x00000000280700E0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectError(ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None))
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_httpcore_exceptions at 0x000000002AB51E40>
    └ <contextlib._GeneratorContextManager object at 0x000000002BFFD5C0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
          │          └ '[WinError 10061] 由于目标计算机积极拒绝，无法连接。'
          └ <class 'httpx.ConnectError'>

httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 20, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          └ <function PDFTranslator.translate_book at 0x000000002885A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A28ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
    │                          │    │     │   │        │                └ 'Chinese'
    │                          │    │     │   │        └ 'English'
    │                          │    │     │   └ <book.content.TableContent object at 0x000000002A995BE0>
    │                          │    │     └ <function TranslatorChain.run at 0x000000002885A200>
    │                          │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A28EE40>
    │                          └ <translator.book_translator.PDFTranslator object at 0x000000002A28ECF0>
    └ ''

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286A7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A28EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB725D0>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2AC2C0>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002BFDFA40>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2AC900>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002ABBB450>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2AC7C0>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2ACA40>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A315EE0>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A983BA0>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A996F90>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x000000000191CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>,)
           └ <function Completions.create at 0x000000002A5E5080>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A28F770>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE2660>
           │    │          └ <openai.OpenAI object at 0x000000002A28F770>
           │    └ ~ResponseT
           └ <function cast at 0x000000000191CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
          │                          └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
          └ <class 'openai.APIConnectionError'>

openai.APIConnectionError: Connection error.
20251114 21:01:43 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 21:01:43 - MainProcess | MainThread | file_writer.save_book_pdf:46 - DEBUG -pdf原文件路径是：test/test.pdf, 翻译之后的输出文件路径: test/test_translated.pdf
20251114 21:01:43 - MainProcess | MainThread | file_writer.save_book_pdf:92 - INFO -pdf文件写入完成！
20251114 21:10:06 - MainProcess | MainThread | pdf_parser.parse_pdf:55 - DEBUG -[pdf解析之后的文本内容]: 
Test Data
This dataset contains two test samples provided by ChatGPT, an AI language model by OpenAI.
These samples include a markdown table and an English text passage, which can be used to test an
English-to-Chinese translation software supporting both text and table formats.
Text testing
The quick brown fox jumps over the lazy dog. This pangram contains every letter of the English
alphabet at least once. Pangrams are often used to test fonts, keyboards, and other text-related
tools. In addition to English, there are pangrams in many other languages. Some pangrams are more
difficult to construct due to the unique characteristics of the language.
Table Testing
20251114 21:10:06 - MainProcess | MainThread | pdf_parser.parse_pdf:61 - DEBUG -[pdf解析之后的表格内容]: 
[[['Fruit', 'Color', 'Price (USD)'], ['Apple', 'Red', '1.20'], ['Banana', 'Yellow', '0.50'], ['Orange', 'Orange', '0.80'], ['Strawberry', 'Red', '2.50'], ['Blueberry', 'Blue', '3.00'], ['Kiwi', 'Green', '1.00'], ['Mango', 'Orange', '1.50'], ['Grape', 'Purple', '2.00']]]
20251114 21:10:13 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Connection error.
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           │    │     │              └ <Request [b'POST']>
           │    │     └ <function ConnectionPool.handle_request at 0x000000002A48DE40>
           │    └ <HTTPProxy [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>
           └ <httpx.HTTPTransport object at 0x000000002A2C79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               │          └ <function TunnelHTTPConnection.handle_request at 0x000000002A48F1A0>
               └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       │    │           └ <function HTTPConnection.handle_request at 0x000000002A48D080>
                       │    └ <HTTPConnection [CONNECTION FAILED]>
                       └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             │    │        └ <Request [b'CONNECT']>
             │    └ <function HTTPConnection._connect at 0x000000002A48D120>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             │    │                │             └ {'host': '127.0.0.1', 'port': 7890, 'local_address': None, 'timeout': None, 'socket_options': None}
             │    │                └ <function SyncBackend.connect_tcp at 0x000000002A431580>
             │    └ <httpcore.SyncBackend object at 0x000000002A2C7D90>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         │              └ {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>}
         └ <function map_exceptions at 0x000000002A403CE0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None)
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_exceptions at 0x000000002A9C3C40>
    └ <contextlib._GeneratorContextManager object at 0x000000002A97A040>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
          └ <class 'httpcore.ConnectError'>

httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               │    │       └ <function Client.send at 0x0000000028073060>
               │    └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
               └ <openai.OpenAI object at 0x000000002A28F770>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               │    └ <function Client._send_handling_auth at 0x0000000028073100>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               │    └ <function Client._send_handling_redirects at 0x00000000280731A0>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               │    │                    └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │    └ <function Client._send_single_request at 0x0000000028073240>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               │         │              └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │         └ <function HTTPTransport.handle_request at 0x00000000280705E0>
               └ <httpx.HTTPTransport object at 0x000000002A2C79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         └ <function map_httpcore_exceptions at 0x00000000280700E0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectError(ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None))
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_httpcore_exceptions at 0x000000002A94BE40>
    └ <contextlib._GeneratorContextManager object at 0x000000002A979CC0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
          │          └ '[WinError 10061] 由于目标计算机积极拒绝，无法连接。'
          └ <class 'httpx.ConnectError'>

httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 20, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          └ <function PDFTranslator.translate_book at 0x000000002885A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A28ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
                               │    │     │   │        │                └ 'Chinese'
                               │    │     │   │        └ 'English'
                               │    │     │   └ <book.content.Content object at 0x000000002A999FD0>
                               │    │     └ <function TranslatorChain.run at 0x000000002885A200>
                               │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A28EE40>
                               └ <translator.book_translator.PDFTranslator object at 0x000000002A28ECF0>

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286A7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A28EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9C2990>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2B0220>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002AB14200>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2B0860>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB34390>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2B0720>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2B09A0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A315E40>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A97FBA0>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A99AF90>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x000000000192CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>,)
           └ <function Completions.create at 0x000000002A5E4FE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A28F770>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE65C0>
           │    │          └ <openai.OpenAI object at 0x000000002A28F770>
           │    └ ~ResponseT
           └ <function cast at 0x000000000192CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
          │                          └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
          └ <class 'openai.APIConnectionError'>

openai.APIConnectionError: Connection error.
20251114 21:10:13 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 21:10:13 - MainProcess | MainThread | content.set_translation:35 - WARNING -当前翻译之后的文本内容不是字符串，请检查！
20251114 21:10:13 - MainProcess | MainThread | translator_chain.run:36 - INFO -+++++++++++++
20251114 21:10:20 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Connection error.
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           │    │     │              └ <Request [b'POST']>
           │    │     └ <function ConnectionPool.handle_request at 0x000000002A48DE40>
           │    └ <HTTPProxy [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>
           └ <httpx.HTTPTransport object at 0x000000002A2C79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               │          └ <function TunnelHTTPConnection.handle_request at 0x000000002A48F1A0>
               └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       │    │           └ <function HTTPConnection.handle_request at 0x000000002A48D080>
                       │    └ <HTTPConnection [CONNECTION FAILED]>
                       └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             │    │        └ <Request [b'CONNECT']>
             │    └ <function HTTPConnection._connect at 0x000000002A48D120>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             │    │                │             └ {'host': '127.0.0.1', 'port': 7890, 'local_address': None, 'timeout': None, 'socket_options': None}
             │    │                └ <function SyncBackend.connect_tcp at 0x000000002A431580>
             │    └ <httpcore.SyncBackend object at 0x000000002A2C7D90>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         │              └ {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>}
         └ <function map_exceptions at 0x000000002A403CE0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None)
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_exceptions at 0x000000002AB516C0>
    └ <contextlib._GeneratorContextManager object at 0x000000002BEFD710>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
          └ <class 'httpcore.ConnectError'>

httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               │    │       └ <function Client.send at 0x0000000028073060>
               │    └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
               └ <openai.OpenAI object at 0x000000002A28F770>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               │    └ <function Client._send_handling_auth at 0x0000000028073100>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               │    └ <function Client._send_handling_redirects at 0x00000000280731A0>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               │    │                    └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │    └ <function Client._send_single_request at 0x0000000028073240>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A28F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               │         │              └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │         └ <function HTTPTransport.handle_request at 0x00000000280705E0>
               └ <httpx.HTTPTransport object at 0x000000002A2C79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         └ <function map_httpcore_exceptions at 0x00000000280700E0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectError(ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None))
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_httpcore_exceptions at 0x000000002AB4DF40>
    └ <contextlib._GeneratorContextManager object at 0x000000002BEFD7F0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
          │          └ '[WinError 10061] 由于目标计算机积极拒绝，无法连接。'
          └ <class 'httpx.ConnectError'>

httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 20, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          └ <function PDFTranslator.translate_book at 0x000000002885A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A28ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
    │                          │    │     │   │        │                └ 'Chinese'
    │                          │    │     │   │        └ 'English'
    │                          │    │     │   └ <book.content.TableContent object at 0x000000002A999BE0>
    │                          │    │     └ <function TranslatorChain.run at 0x000000002885A200>
    │                          │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A28EE40>
    │                          └ <translator.book_translator.PDFTranslator object at 0x000000002A28ECF0>
    └ ''

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286A7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A28EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB725D0>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2B0220>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002BF0C300>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2B0860>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002ABBB450>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2B0720>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2B09A0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A315E40>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A97FBA0>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A99AF90>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x000000000192CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>,)
           └ <function Completions.create at 0x000000002A5E4FE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A28F770>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A45FCB0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE65C0>
           │    │          └ <openai.OpenAI object at 0x000000002A28F770>
           │    └ ~ResponseT
           └ <function cast at 0x000000000192CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
          │                          └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
          └ <class 'openai.APIConnectionError'>

openai.APIConnectionError: Connection error.
20251114 21:10:20 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 21:10:20 - MainProcess | MainThread | file_writer.save_book_pdf:46 - DEBUG -pdf原文件路径是：test/test.pdf, 翻译之后的输出文件路径: test/test_translated.pdf
20251114 21:10:21 - MainProcess | MainThread | file_writer.save_book_pdf:92 - INFO -pdf文件写入完成！
20251114 21:15:46 - MainProcess | MainThread | pdf_parser.parse_pdf:55 - DEBUG -[pdf解析之后的文本内容]: 
Test Data
This dataset contains two test samples provided by ChatGPT, an AI language model by OpenAI.
These samples include a markdown table and an English text passage, which can be used to test an
English-to-Chinese translation software supporting both text and table formats.
Text testing
The quick brown fox jumps over the lazy dog. This pangram contains every letter of the English
alphabet at least once. Pangrams are often used to test fonts, keyboards, and other text-related
tools. In addition to English, there are pangrams in many other languages. Some pangrams are more
difficult to construct due to the unique characteristics of the language.
Table Testing
20251114 21:15:46 - MainProcess | MainThread | pdf_parser.parse_pdf:61 - DEBUG -[pdf解析之后的表格内容]: 
[[['Fruit', 'Color', 'Price (USD)'], ['Apple', 'Red', '1.20'], ['Banana', 'Yellow', '0.50'], ['Orange', 'Orange', '0.80'], ['Strawberry', 'Red', '2.50'], ['Blueberry', 'Blue', '3.00'], ['Kiwi', 'Green', '1.00'], ['Mango', 'Orange', '1.50'], ['Grape', 'Purple', '2.00']]]
20251114 21:15:47 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Error code: 401 - {'error': {'message': 'Incorrect API key provided: b6a313e3*************************************SwkA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 23, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          └ <function PDFTranslator.translate_book at 0x000000002885A0C0>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
                               │    │     │   │        │                └ 'Chinese'
                               │    │     │   │        └ 'English'
                               │    │     │   └ <book.content.Content object at 0x000000002A99DA90>
                               │    │     └ <function TranslatorChain.run at 0x000000002885A2A0>
                               │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>
                               └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286A7EC0>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9CAA80>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2B8360>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002AB30480>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2B89A0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB3C390>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2B8860>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2B8AE0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A325F80>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A98FB00>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A99EA50>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x00000000018CCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>,)
           └ <function Completions.create at 0x000000002A5F5080>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A46D010>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE6700>
           │    │          └ <openai.OpenAI object at 0x000000002A46D010>
           │    └ ~ResponseT
           └ <function cast at 0x00000000018CCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
          │    └ <function BaseClient._make_status_error_from_response at 0x0000000026EE4EA0>
          └ <openai.OpenAI object at 0x000000002A46D010>

openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: b6a313e3*************************************SwkA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
20251114 21:15:47 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 21:15:47 - MainProcess | MainThread | content.set_translation:35 - WARNING -当前翻译之后的文本内容不是字符串，请检查！
20251114 21:15:47 - MainProcess | MainThread | translator_chain.run:36 - INFO -+++++++++++++
20251114 21:15:47 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Error code: 401 - {'error': {'message': 'Incorrect API key provided: b6a313e3*************************************SwkA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 23, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          └ <function PDFTranslator.translate_book at 0x000000002885A0C0>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
    │                          │    │     │   │        │                └ 'Chinese'
    │                          │    │     │   │        └ 'English'
    │                          │    │     │   └ <book.content.TableContent object at 0x000000002A99D6A0>
    │                          │    │     └ <function TranslatorChain.run at 0x000000002885A2A0>
    │                          │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>
    │                          └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>
    └ ''

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286A7EC0>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9A3F50>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2B8360>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002AB160C0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2B89A0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9A3B50>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2B8860>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2B8AE0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A325F80>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A98FB00>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A99EA50>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x00000000018CCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>,)
           └ <function Completions.create at 0x000000002A5F5080>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A46D010>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE6700>
           │    │          └ <openai.OpenAI object at 0x000000002A46D010>
           │    └ ~ResponseT
           └ <function cast at 0x00000000018CCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
          │    └ <function BaseClient._make_status_error_from_response at 0x0000000026EE4EA0>
          └ <openai.OpenAI object at 0x000000002A46D010>

openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: b6a313e3*************************************SwkA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
20251114 21:15:47 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 21:15:47 - MainProcess | MainThread | file_writer.save_book_pdf:46 - DEBUG -pdf原文件路径是：test/test.pdf, 翻译之后的输出文件路径: test/test_translated.pdf
20251114 21:15:47 - MainProcess | MainThread | file_writer.save_book_pdf:92 - INFO -pdf文件写入完成！
20251114 21:20:35 - MainProcess | MainThread | pdf_parser.parse_pdf:55 - DEBUG -[pdf解析之后的文本内容]: 
Test Data
This dataset contains two test samples provided by ChatGPT, an AI language model by OpenAI.
These samples include a markdown table and an English text passage, which can be used to test an
English-to-Chinese translation software supporting both text and table formats.
Text testing
The quick brown fox jumps over the lazy dog. This pangram contains every letter of the English
alphabet at least once. Pangrams are often used to test fonts, keyboards, and other text-related
tools. In addition to English, there are pangrams in many other languages. Some pangrams are more
difficult to construct due to the unique characteristics of the language.
Table Testing
20251114 21:20:35 - MainProcess | MainThread | pdf_parser.parse_pdf:61 - DEBUG -[pdf解析之后的表格内容]: 
[[['Fruit', 'Color', 'Price (USD)'], ['Apple', 'Red', '1.20'], ['Banana', 'Yellow', '0.50'], ['Orange', 'Orange', '0.80'], ['Strawberry', 'Red', '2.50'], ['Blueberry', 'Blue', '3.00'], ['Kiwi', 'Green', '1.00'], ['Mango', 'Orange', '1.50'], ['Grape', 'Purple', '2.00']]]
20251114 21:20:42 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Connection error.
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           │    │     │              └ <Request [b'POST']>
           │    │     └ <function ConnectionPool.handle_request at 0x000000002A49DEE0>
           │    └ <HTTPProxy [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>
           └ <httpx.HTTPTransport object at 0x000000002A2D79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               │          └ <function TunnelHTTPConnection.handle_request at 0x000000002A49F240>
               └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       │    │           └ <function HTTPConnection.handle_request at 0x000000002A49D120>
                       │    └ <HTTPConnection [CONNECTION FAILED]>
                       └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             │    │        └ <Request [b'CONNECT']>
             │    └ <function HTTPConnection._connect at 0x000000002A49D1C0>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             │    │                │             └ {'host': '127.0.0.1', 'port': 7890, 'local_address': None, 'timeout': None, 'socket_options': None}
             │    │                └ <function SyncBackend.connect_tcp at 0x000000002A43D620>
             │    └ <httpcore.SyncBackend object at 0x000000002A2D7D90>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         │              └ {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>}
         └ <function map_exceptions at 0x000000002A413D80>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None)
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_exceptions at 0x000000002A9D3C40>
    └ <contextlib._GeneratorContextManager object at 0x000000002A98DFD0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
          └ <class 'httpcore.ConnectError'>

httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               │    │       └ <function Client.send at 0x0000000028073060>
               │    └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
               └ <openai.OpenAI object at 0x000000002A29F770>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               │    └ <function Client._send_handling_auth at 0x0000000028073100>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               │    └ <function Client._send_handling_redirects at 0x00000000280731A0>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               │    │                    └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │    └ <function Client._send_single_request at 0x0000000028073240>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               │         │              └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │         └ <function HTTPTransport.handle_request at 0x00000000280705E0>
               └ <httpx.HTTPTransport object at 0x000000002A2D79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         └ <function map_httpcore_exceptions at 0x00000000280700E0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectError(ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None))
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_httpcore_exceptions at 0x000000002A95BD40>
    └ <contextlib._GeneratorContextManager object at 0x000000002A98DC50>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
          │          └ '[WinError 10061] 由于目标计算机积极拒绝，无法连接。'
          └ <class 'httpx.ConnectError'>

httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 22, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          └ <function PDFTranslator.translate_book at 0x000000002885A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
                               │    │     │   │        │                └ 'Chinese'
                               │    │     │   │        └ 'English'
                               │    │     │   └ <book.content.Content object at 0x000000002A9A9FD0>
                               │    │     └ <function TranslatorChain.run at 0x000000002885A200>
                               │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>
                               └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286A7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9D2990>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2BC2C0>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002AB30140>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2BC900>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB44390>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2BC7C0>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2BCA40>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A325EE0>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A993BA0>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A9AAF90>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x000000000191CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>,)
           └ <function Completions.create at 0x000000002A5F5080>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A29F770>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE6660>
           │    │          └ <openai.OpenAI object at 0x000000002A29F770>
           │    └ ~ResponseT
           └ <function cast at 0x000000000191CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
          │                          └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
          └ <class 'openai.APIConnectionError'>

openai.APIConnectionError: Connection error.
20251114 21:20:42 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 21:20:42 - MainProcess | MainThread | content.set_translation:35 - WARNING -当前翻译之后的文本内容不是字符串，请检查！
20251114 21:20:42 - MainProcess | MainThread | translator_chain.run:36 - INFO -+++++++++++++
20251114 21:20:50 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Connection error.
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           │    │     │              └ <Request [b'POST']>
           │    │     └ <function ConnectionPool.handle_request at 0x000000002A49DEE0>
           │    └ <HTTPProxy [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>
           └ <httpx.HTTPTransport object at 0x000000002A2D79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               │          └ <function TunnelHTTPConnection.handle_request at 0x000000002A49F240>
               └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       │    │           └ <function HTTPConnection.handle_request at 0x000000002A49D120>
                       │    └ <HTTPConnection [CONNECTION FAILED]>
                       └ <TunnelHTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             │    │        └ <Request [b'CONNECT']>
             │    └ <function HTTPConnection._connect at 0x000000002A49D1C0>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             │    │                │             └ {'host': '127.0.0.1', 'port': 7890, 'local_address': None, 'timeout': None, 'socket_options': None}
             │    │                └ <function SyncBackend.connect_tcp at 0x000000002A43D620>
             │    └ <httpcore.SyncBackend object at 0x000000002A2D7D90>
             └ <HTTPConnection [CONNECTION FAILED]>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         │              └ {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>}
         └ <function map_exceptions at 0x000000002A413D80>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None)
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_exceptions at 0x000000002AB5D6C0>
    └ <contextlib._GeneratorContextManager object at 0x000000002AF3D6A0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
          └ <class 'httpcore.ConnectError'>

httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               │    │       └ <function Client.send at 0x0000000028073060>
               │    └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
               └ <openai.OpenAI object at 0x000000002A29F770>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               │    └ <function Client._send_handling_auth at 0x0000000028073100>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               │    └ <function Client._send_handling_redirects at 0x00000000280731A0>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               │    │                    └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │    └ <function Client._send_single_request at 0x0000000028073240>
               └ <langchain_openai.chat_models._client_utils._SyncHttpxClientWrapper object at 0x000000002A29F0E0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               │         │              └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
               │         └ <function HTTPTransport.handle_request at 0x00000000280705E0>
               └ <httpx.HTTPTransport object at 0x000000002A2D79D0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         └ <function map_httpcore_exceptions at 0x00000000280700E0>
  File "C:\Users\longdingyu\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 162, in __exit__
    self.gen.throw(value)
    │    │   │     └ ConnectError(ConnectionRefusedError(10061, '由于目标计算机积极拒绝，无法连接。', None, 10061, None))
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object map_httpcore_exceptions at 0x000000002AB61E40>
    └ <contextlib._GeneratorContextManager object at 0x000000002AF3D780>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
          │          └ '[WinError 10061] 由于目标计算机积极拒绝，无法连接。'
          └ <class 'httpx.ConnectError'>

httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 22, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          │              └ <utils.project_config.ProjectConfig object at 0x0000000028616270>
    │          └ <function PDFTranslator.translate_book at 0x000000002885A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
    │                          │    │     │   │        │                └ 'Chinese'
    │                          │    │     │   │        └ 'English'
    │                          │    │     │   └ <book.content.TableContent object at 0x000000002A9A9BE0>
    │                          │    │     └ <function TranslatorChain.run at 0x000000002885A200>
    │                          │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>
    │                          └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>
    └ ''

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286A7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB825D0>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2BC2C0>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002AF50300>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2BC900>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002ABCB450>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2BC7C0>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2BCA40>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A325EE0>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A993BA0>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A9AAF90>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x000000000191CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>,)
           └ <function Completions.create at 0x000000002A5F5080>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A29F770>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46FCB0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EE6660>
           │    │          └ <openai.OpenAI object at 0x000000002A29F770>
           │    └ ~ResponseT
           └ <function cast at 0x000000000191CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
          │                          └ <Request('POST', 'https://api.openai.com/v1/chat/completions')>
          └ <class 'openai.APIConnectionError'>

openai.APIConnectionError: Connection error.
20251114 21:20:50 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 21:20:50 - MainProcess | MainThread | file_writer.save_book_pdf:46 - DEBUG -pdf原文件路径是：test/test.pdf, 翻译之后的输出文件路径: test/test_translated.pdf
20251114 21:20:50 - MainProcess | MainThread | file_writer.save_book_pdf:92 - INFO -pdf文件写入完成！
20251114 21:23:33 - MainProcess | MainThread | pdf_parser.parse_pdf:55 - DEBUG -[pdf解析之后的文本内容]: 
Test Data
This dataset contains two test samples provided by ChatGPT, an AI language model by OpenAI.
These samples include a markdown table and an English text passage, which can be used to test an
English-to-Chinese translation software supporting both text and table formats.
Text testing
The quick brown fox jumps over the lazy dog. This pangram contains every letter of the English
alphabet at least once. Pangrams are often used to test fonts, keyboards, and other text-related
tools. In addition to English, there are pangrams in many other languages. Some pangrams are more
difficult to construct due to the unique characteristics of the language.
Table Testing
20251114 21:23:33 - MainProcess | MainThread | pdf_parser.parse_pdf:61 - DEBUG -[pdf解析之后的表格内容]: 
[[['Fruit', 'Color', 'Price (USD)'], ['Apple', 'Red', '1.20'], ['Banana', 'Yellow', '0.50'], ['Orange', 'Orange', '0.80'], ['Strawberry', 'Red', '2.50'], ['Blueberry', 'Blue', '3.00'], ['Kiwi', 'Green', '1.00'], ['Mango', 'Orange', '1.50'], ['Grape', 'Purple', '2.00']]]
20251114 21:23:35 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Error code: 401 - {'error': {'message': 'Incorrect API key provided: b6a313e3*************************************SwkA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 23, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          └ <function PDFTranslator.translate_book at 0x000000002886A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A2AECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
                               │    │     │   │        │                └ 'Chinese'
                               │    │     │   │        └ 'English'
                               │    │     │   └ <book.content.Content object at 0x000000002A9B1A90>
                               │    │     └ <function TranslatorChain.run at 0x000000002886A200>
                               │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A2AEE40>
                               └ <translator.book_translator.PDFTranslator object at 0x000000002A2AECF0>

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286B7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A2AEE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9DAA80>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2D0220>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002AB41680>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2D0860>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB4C390>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2D0720>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2D09A0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A335E40>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A99FBA0>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A9B2A50>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x000000000197CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>,)
           └ <function Completions.create at 0x000000002A604F40>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A47D010>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EF25C0>
           │    │          └ <openai.OpenAI object at 0x000000002A47D010>
           │    └ ~ResponseT
           └ <function cast at 0x000000000197CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
          │    └ <function BaseClient._make_status_error_from_response at 0x0000000026EF0D60>
          └ <openai.OpenAI object at 0x000000002A47D010>

openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: b6a313e3*************************************SwkA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
20251114 21:23:35 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 21:23:35 - MainProcess | MainThread | content.set_translation:35 - WARNING -当前翻译之后的文本内容不是字符串，请检查！
20251114 21:23:35 - MainProcess | MainThread | translator_chain.run:36 - INFO -+++++++++++++
20251114 21:23:35 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Error code: 401 - {'error': {'message': 'Incorrect API key provided: b6a313e3*************************************SwkA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 23, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          │              └ <utils.project_config.ProjectConfig object at 0x000000002875A900>
    │          └ <function PDFTranslator.translate_book at 0x000000002886A020>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A2AECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
    │                          │    │     │   │        │                └ 'Chinese'
    │                          │    │     │   │        └ 'English'
    │                          │    │     │   └ <book.content.TableContent object at 0x000000002A9B16A0>
    │                          │    │     └ <function TranslatorChain.run at 0x000000002886A200>
    │                          │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A2AEE40>
    │                          └ <translator.book_translator.PDFTranslator object at 0x000000002A2AECF0>
    └ ''

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286B7E20>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A2AEE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9B7ED0>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2D0220>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002AB25E00>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2D0860>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9B7AD0>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2D0720>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2D09A0>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A335E40>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A99FBA0>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A9B2A50>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x000000000197CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>,)
           └ <function Completions.create at 0x000000002A604F40>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A47D010>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A47F8C0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026EF25C0>
           │    │          └ <openai.OpenAI object at 0x000000002A47D010>
           │    └ ~ResponseT
           └ <function cast at 0x000000000197CFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
          │    └ <function BaseClient._make_status_error_from_response at 0x0000000026EF0D60>
          └ <openai.OpenAI object at 0x000000002A47D010>

openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: b6a313e3*************************************SwkA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
20251114 21:23:35 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 21:23:35 - MainProcess | MainThread | file_writer.save_book_pdf:46 - DEBUG -pdf原文件路径是：test/test.pdf, 翻译之后的输出文件路径: test/test_translated.pdf
20251114 21:23:35 - MainProcess | MainThread | file_writer.save_book_pdf:92 - INFO -pdf文件写入完成！
20251114 21:28:57 - MainProcess | MainThread | pdf_parser.parse_pdf:55 - DEBUG -[pdf解析之后的文本内容]: 
Test Data
This dataset contains two test samples provided by ChatGPT, an AI language model by OpenAI.
These samples include a markdown table and an English text passage, which can be used to test an
English-to-Chinese translation software supporting both text and table formats.
Text testing
The quick brown fox jumps over the lazy dog. This pangram contains every letter of the English
alphabet at least once. Pangrams are often used to test fonts, keyboards, and other text-related
tools. In addition to English, there are pangrams in many other languages. Some pangrams are more
difficult to construct due to the unique characteristics of the language.
Table Testing
20251114 21:28:57 - MainProcess | MainThread | pdf_parser.parse_pdf:61 - DEBUG -[pdf解析之后的表格内容]: 
[[['Fruit', 'Color', 'Price (USD)'], ['Apple', 'Red', '1.20'], ['Banana', 'Yellow', '0.50'], ['Orange', 'Orange', '0.80'], ['Strawberry', 'Red', '2.50'], ['Blueberry', 'Blue', '3.00'], ['Kiwi', 'Green', '1.00'], ['Mango', 'Orange', '1.50'], ['Grape', 'Purple', '2.00']]]
20251114 21:28:58 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Error code: 401 - {'error': {'message': 'Incorrect API key provided: b6a313e3*************************************SwkA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 26, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          └ <function PDFTranslator.translate_book at 0x000000002885A0C0>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
                               │    │     │   │        │                └ 'Chinese'
                               │    │     │   │        └ 'English'
                               │    │     │   └ <book.content.Content object at 0x000000002A9A1A90>
                               │    │     └ <function TranslatorChain.run at 0x000000002885A2A0>
                               │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>
                               └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286A7EC0>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9CA990>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2BC2C0>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002AB33980>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2BC900>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002AB3C390>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2BC7C0>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2BCA40>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A325EE0>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A98FB00>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A9A2A50>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x00000000019BCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>,)
           └ <function Completions.create at 0x000000002A5F4FE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A46D010>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026F32660>
           │    │          └ <openai.OpenAI object at 0x000000002A46D010>
           │    └ ~ResponseT
           └ <function cast at 0x00000000019BCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
          │    └ <function BaseClient._make_status_error_from_response at 0x0000000026F30E00>
          └ <openai.OpenAI object at 0x000000002A46D010>

openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: b6a313e3*************************************SwkA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
20251114 21:28:58 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 21:28:58 - MainProcess | MainThread | content.set_translation:35 - WARNING -当前翻译之后的文本内容不是字符串，请检查！
20251114 21:28:58 - MainProcess | MainThread | translator_chain.run:36 - INFO -+++++++++++++
20251114 21:29:00 - MainProcess | MainThread | translator_chain.run:46 - ERROR -Error code: 401 - {'error': {'message': 'Incorrect API key provided: b6a313e3*************************************SwkA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
Traceback (most recent call last):

  File "E:\PythonProjector\Langchain_BookTranslator\main.py", line 26, in <module>
    translator.translate_book(config.input_file, config.source_language, config.target_language, config.file_format)
    │          │              │                  │                       │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  │                       └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              │                  └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          │              └ <utils.project_config.ProjectConfig object at 0x000000002874A900>
    │          └ <function PDFTranslator.translate_book at 0x000000002885A0C0>
    └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>

  File "E:\PythonProjector\Langchain_BookTranslator\translator\book_translator.py", line 38, in translate_book
    translation_text, status = self.chain.run(content, source_language, target_language)
    │                          │    │     │   │        │                └ 'Chinese'
    │                          │    │     │   │        └ 'English'
    │                          │    │     │   └ <book.content.TableContent object at 0x000000002A9A16A0>
    │                          │    │     └ <function TranslatorChain.run at 0x000000002885A2A0>
    │                          │    └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>
    │                          └ <translator.book_translator.PDFTranslator object at 0x000000002A29ECF0>
    └ ''

> File "E:\PythonProjector\Langchain_BookTranslator\translator\translator_chain.py", line 39, in run
    result = self.langchain.invoke({
             │    │         └ <function RunnableSequence.invoke at 0x00000000286A7EC0>
             │    └ ChatPromptTemplate(input_variables=['source_language', 'target_language', 'text'], input_types={}, partial_variables={}, mess...
             └ <translator.translator_chain.TranslatorChain object at 0x000000002A29EE40>

  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3129, in invoke
    input_ = context.run(step.invoke, input_, config)
             │       │   │    │       │       └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9A7ED0>, 'r...
             │       │   │    │       └ ChatPromptValue(messages=[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_...
             │       │   │    └ <function BaseChatModel.invoke at 0x000000002A2BC2C0>
             │       │   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
             │       └ <method 'run' of '_contextvars.Context' objects>
             └ <_contextvars.Context object at 0x000000002AB19D80>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 382, in invoke
    self.generate_prompt(
    │    └ <function BaseChatModel.generate_prompt at 0x000000002A2BC900>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1101, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           │    │        │                     │               │            └ {'tags': [], 'metadata': {}, 'run_name': None, 'run_id': None}
           │    │        │                     │               └ <langchain_core.callbacks.manager.CallbackManager object at 0x000000002A9A7AD0>
           │    │        │                     └ None
           │    │        └ [[SystemMessage(content='你是一个翻译专家，精通各种人类语言。\n\n        输入的是：English 语言，翻译之后的语言为：Chinese', additional_kwargs={}, response_meta...
           │    └ <function BaseChatModel.generate at 0x000000002A2BC7C0>
           └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 911, in generate
    self._generate_with_cache(
    │    └ <function BaseChatModel._generate_with_cache at 0x000000002A2BCA40>
    └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1205, in _generate_with_cache
    result = self._generate(
             │    └ <function BaseChatOpenAI._generate at 0x000000002A325EE0>
             └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1299, in _generate
    raise e
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1294, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   │    │      │                 │        └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
                   │    │      │                 └ <function Completions.create at 0x000000002A98FB00>
                   │    │      └ <openai.resources.chat.completions.completions.CompletionsWithRawResponse object at 0x000000002A9A2A50>
                   │    └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>
                   └ ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>, async_client=<ope...
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
           │    │                 │   │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │    │                 │   │     └ ()
           │    │                 │   └ <bound method Completions.create of <openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>>
           │    │                 └ ~R
           │    └ <class 'openai._legacy_response.LegacyAPIResponse'>
           └ <function cast at 0x00000000019BCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           │     │       └ {'model': 'GLM-4.5', 'stream': False, 'temperature': 0.5, 'messages': [{'content': '你是一个翻译专家，精通各种人类语言。\n\n        输入的是：Englis...
           │     └ (<openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>,)
           └ <function Completions.create at 0x000000002A5F4FE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x000000002A46D010>>
           └ <openai.resources.chat.completions.completions.Completions object at 0x000000002A46F8C0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
           │    │          │    │       │        │            └ False
           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers={'X-Stainless-Raw-Response': 'true'}, max_retr...
           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>
           │    │          │    └ <function SyncAPIClient.request at 0x0000000026F32660>
           │    │          └ <openai.OpenAI object at 0x000000002A46D010>
           │    └ ~ResponseT
           └ <function cast at 0x00000000019BCFE0>
  File "E:\PythonProjector\Langchain_BookTranslator\.venv\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
          │    └ <function BaseClient._make_status_error_from_response at 0x0000000026F30E00>
          └ <openai.OpenAI object at 0x000000002A46D010>

openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: b6a313e3*************************************SwkA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
20251114 21:29:00 - MainProcess | MainThread | book_translator.translate_book:39 - DEBUG -翻译之后的内容是: 
 
20251114 21:29:00 - MainProcess | MainThread | file_writer.save_book_pdf:46 - DEBUG -pdf原文件路径是：test/test.pdf, 翻译之后的输出文件路径: test/test_translated.pdf
20251114 21:29:00 - MainProcess | MainThread | file_writer.save_book_pdf:92 - INFO -pdf文件写入完成！
